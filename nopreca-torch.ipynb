{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":192486486,"sourceType":"kernelVersion"}],"dockerImageVersionId":30664,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset, random_split\nimport numpy as np\nfrom sklearn.metrics import roc_auc_score, precision_recall_curve, auc\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\ndf_train = pd.read_csv('/kaggle/input/tcr-attencross-data/train.csv')\ndf_train = df_train.drop(columns=['Unnamed: 0.1', 'Unnamed: 0'])\ntcr_features = df_train.filter(like='TCR_').columns\nhla_features = df_train.columns.drop(tcr_features).drop('label')\nX_tcr_train = df_train[tcr_features]\nX_hla_train = df_train[hla_features]\ny_train = df_train['label']\ny = df_train['label']\ndf_test = pd.read_csv('/kaggle/input/tcr-attencross-data/test.csv')\ndf_test = df_test.drop(columns=['Unnamed: 0.1', 'Unnamed: 0'])\nX_tcr_test = df_test[tcr_features]\nX_hla_test = df_test[hla_features]\ny_test = df_test['label']\ndf_independed = pd.read_csv('/kaggle/input/tcr-attencross-data/independent_test.csv')\nX_tcr_independed = df_independed[tcr_features]\nX_hla_independed = df_independed[hla_features]\ny_independed = df_independed['label']","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-13T12:12:06.395272Z","iopub.execute_input":"2024-08-13T12:12:06.396051Z","iopub.status.idle":"2024-08-13T12:12:29.548629Z","shell.execute_reply.started":"2024-08-13T12:12:06.395999Z","shell.execute_reply":"2024-08-13T12:12:29.547828Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class TCR_pMHC_Cross(nn.Module):\n    def __init__(self, input_dim_1=5, input_dim_2=1, seq_len_1=20, seq_len_2=60, d_model=64):\n        super(TCR_pMHC_Cross, self).__init__()\n        self.positional_encoding_1 = nn.Parameter(torch.randn(1, seq_len_1, d_model))\n        self.positional_encoding_2 = nn.Parameter(torch.randn(1, seq_len_2, d_model))\n        self.linear_in_1 = nn.Linear(input_dim_1, d_model) \n        self.linear_in_2 = nn.Linear(input_dim_2, d_model)\n        self.cross_attn = nn.MultiheadAttention(embed_dim=d_model, num_heads=4, batch_first=True)\n        self.layer_norm = nn.LayerNorm(d_model)\n        self.feed_forward = nn.Sequential(\n            nn.Linear(d_model, d_model * 4),\n            nn.ReLU(),\n            nn.Linear(d_model * 4, d_model)\n        )\n\n    def forward(self, x1, x2):\n        x2 = x2.unsqueeze(-1)\n        x1 = self.linear_in_1(x1) + self.positional_encoding_1\n        x2 = self.linear_in_2(x2) + self.positional_encoding_2\n        attn_output, _ = self.cross_attn(query=x2, key=x1, value=x1)\n        x1_norm = self.layer_norm(attn_output + x2)\n        ff_output = self.feed_forward(x1_norm)\n        output = self.layer_norm(ff_output + x1_norm)\n        return output\n\n    \nclass THACrossModel(nn.Module):\n    def __init__(self):\n        super(THACrossModel, self).__init__()\n        input_features = 64 + 20*5 + 60\n        self.fc_sequence = nn.Sequential(\n            nn.Linear(input_features, 1024),\n            nn.ReLU(),\n            nn.Dropout(0.1),\n            nn.Linear(1024, 1024),\n            nn.ReLU(),\n            nn.Dropout(0.1),\n            nn.Linear(1024, 2),\n            nn.Sigmoid()\n        )\n        self.tcr_pMHC = TCR_pMHC_Cross()\n\n    def forward(self, x_tcr, x_antigen_hla):\n        x_tcr_flat = x_tcr.view(x_tcr.size(0), -1)\n        tcr_pMHC_matrix = self.tcr_pMHC(x_tcr, x_antigen_hla)\n        tcr_pMHC_flat = tcr_pMHC_matrix.mean(dim=1)\n        x = torch.cat((x_tcr_flat, x_antigen_hla, tcr_pMHC_flat), dim=1)\n        out = self.fc_sequence(x) \n        return out","metadata":{"execution":{"iopub.status.busy":"2024-08-13T12:12:29.550271Z","iopub.execute_input":"2024-08-13T12:12:29.550620Z","iopub.status.idle":"2024-08-13T12:12:29.564382Z","shell.execute_reply.started":"2024-08-13T12:12:29.550593Z","shell.execute_reply":"2024-08-13T12:12:29.563470Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train(model, train_loader, val_loader, loss_function, optimizer, epochs=5):\n    train_losses, val_losses, val_accuracies = [], [], []\n    for epoch in range(epochs):\n        model.train() \n        total_loss = 0 \n        for X_tcr_batch, X_hla_batch, y_batch in train_loader:\n            X_tcr_batch, X_hla_batch, y_batch = X_tcr_batch.to(device), X_hla_batch.to(device), y_batch.to(device)\n            optimizer.zero_grad()  \n            outputs = model(X_tcr_batch, X_hla_batch) \n            loss = loss_function(outputs, y_batch.squeeze()) \n            loss.backward()  \n            optimizer.step()  \n            total_loss += loss.item() \n        \n        train_losses.append(total_loss / len(train_loader))\n        \n        model.eval()  \n        total_val_loss = 0\n        correct = 0  \n        with torch.no_grad():  \n            for X_tcr_batch, X_hla_batch, y_batch in val_loader:\n                X_tcr_batch, X_hla_batch, y_batch = X_tcr_batch.to(device), X_hla_batch.to(device), y_batch.to(device)\n                outputs = model(X_tcr_batch, X_hla_batch)  \n                total_val_loss += loss_function(outputs, y_batch.squeeze()).item()  \n                predicted = outputs.argmax(dim=1)  \n                correct += (predicted == y_batch.squeeze()).sum().item() \n        \n        val_losses.append(total_val_loss / len(val_loader))\n        val_accuracies.append(correct / len(val_loader.dataset))\n        print(f\"Epoch {epoch+1}, Train Loss: {train_losses[-1]}, Val Loss: {val_losses[-1]}, Val Accuracy: {val_accuracies[-1]}\")\n    \n    return train_losses, val_losses, val_accuracies","metadata":{"execution":{"iopub.status.busy":"2024-08-13T12:12:29.565595Z","iopub.execute_input":"2024-08-13T12:12:29.565969Z","iopub.status.idle":"2024-08-13T12:12:29.580062Z","shell.execute_reply.started":"2024-08-13T12:12:29.565938Z","shell.execute_reply":"2024-08-13T12:12:29.579253Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import TensorDataset, DataLoader\nimport torch.optim as optim\nimport numpy as np\nbatch_size = 128\nX_tcr_np = X_tcr_train.to_numpy().astype(np.float32).reshape(-1, 20, 5)\nX_tcr_tensor = torch.tensor(X_tcr_np)\nX_hla_np = X_hla_train.to_numpy().astype(np.float32)\nX_hla_tensor = torch.tensor(X_hla_np)\ny_tensor = torch.tensor(y_train.to_numpy()).long()\ny_tensor = y_tensor.reshape(y_tensor.shape[0],1)##\nX_tcr_train_, X_tcr_val_, X_hla_train_, X_hla_val_, y_train_, y_val_ = train_test_split(\n    X_tcr_tensor, X_hla_tensor, y_tensor, test_size=0.2, random_state=42)\ntrain_dataset = TensorDataset(X_tcr_train_, X_hla_train_, y_train_)\nval_dataset = TensorDataset(X_tcr_val_, X_hla_val_, y_val_)\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = THACrossModel().to(device)\nprint(model)\nloss_function = nn.CrossEntropyLoss()\noptimizer = optim.SGD(model.parameters(), lr=0.01)\ntrain_losses, val_losses, val_accuracies = train(model, train_loader, val_loader, loss_function, optimizer, epochs=200)","metadata":{"execution":{"iopub.status.busy":"2024-08-13T12:12:29.581761Z","iopub.execute_input":"2024-08-13T12:12:29.582458Z","iopub.status.idle":"2024-08-13T12:14:28.947532Z","shell.execute_reply.started":"2024-08-13T12:12:29.582405Z","shell.execute_reply":"2024-08-13T12:14:28.946592Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.figure(figsize=(12, 5))\nplt.subplot(1, 2, 1)\nplt.plot(train_losses, label='Train Loss')\nplt.plot(val_losses, label='Validation Loss')\nplt.legend()\nplt.title('Loss over epochs')\nplt.subplot(1, 2, 2)\nplt.plot(val_accuracies)\nplt.title('Validation Accuracy over epochs')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-08-13T12:14:28.948704Z","iopub.execute_input":"2024-08-13T12:14:28.949005Z","iopub.status.idle":"2024-08-13T12:14:29.428501Z","shell.execute_reply.started":"2024-08-13T12:14:28.948979Z","shell.execute_reply":"2024-08-13T12:14:29.427572Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve, precision_recall_curve, auc, f1_score, precision_recall_fscore_support\nfrom sklearn.calibration import calibration_curve\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport torch\nfrom torch.utils.data import TensorDataset, DataLoader\nfrom torch.nn.functional import softmax\nfrom sklearn.metrics import matthews_corrcoef\n\nX_tcr_test_np = X_tcr_test.to_numpy().astype(np.float32).reshape(-1, 20, 5)\nX_hla_test_np = X_hla_test.to_numpy().astype(np.float32)\ny_test_np = y_test.to_numpy().astype(np.int64)\nX_tcr_test_tensor = torch.tensor(X_tcr_test_np)\nX_hla_test_tensor = torch.tensor(X_hla_test_np)\ny_test_tensor = torch.tensor(y_test_np).long()\ntest_dataset = TensorDataset(X_tcr_test_tensor, X_hla_test_tensor, y_test_tensor)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\nmodel.eval()\nprob_predictions = []\npredictions = []\nreal_labels = []\n\nwith torch.no_grad():\n    for X_tcr_batch, X_hla_batch, y_batch in test_loader:\n        X_tcr_batch, X_hla_batch, y_batch = X_tcr_batch.to(device), X_hla_batch.to(device), y_batch.to(device)\n        logits = model(X_tcr_batch, X_hla_batch)\n        _, predicted = torch.max(logits.data, 1)\n        probs = softmax(logits, dim=1)[:, 1]  \n        predictions.extend(predicted.cpu().numpy())\n        prob_predictions.extend(probs.cpu().numpy())\n        real_labels.extend(y_batch.cpu().numpy())\n\npredictions = np.array(predictions)\nprob_predictions = np.array(prob_predictions)\nreal_labels = np.array(real_labels).flatten()\n\nresults_df = pd.DataFrame({\n    'Predictions': predictions,\n    'Probability Predictions': prob_predictions,\n    'Real Labels': real_labels\n})\nresults_df.to_csv('test_results.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2024-08-13T12:14:29.429923Z","iopub.execute_input":"2024-08-13T12:14:29.430213Z","iopub.status.idle":"2024-08-13T12:14:37.612460Z","shell.execute_reply.started":"2024-08-13T12:14:29.430188Z","shell.execute_reply":"2024-08-13T12:14:37.611051Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_tcr_test_np = X_tcr_independed.to_numpy().astype(np.float32).reshape(-1, 20, 5)\nX_hla_test_np = X_hla_independed.to_numpy().astype(np.float32)\ny_test_np = y_independed.to_numpy().astype(np.int64)\nX_tcr_test_tensor = torch.tensor(X_tcr_test_np)\nX_hla_test_tensor = torch.tensor(X_hla_test_np)\ny_test_tensor = torch.tensor(y_test_np).long()\ntest_dataset = TensorDataset(X_tcr_test_tensor, X_hla_test_tensor, y_test_tensor)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\nmodel.eval()\nprob_predictions = []\npredictions = []\nreal_labels = []\n\nwith torch.no_grad():\n    for X_tcr_batch, X_hla_batch, y_batch in test_loader:\n        X_tcr_batch, X_hla_batch, y_batch = X_tcr_batch.to(device), X_hla_batch.to(device), y_batch.to(device)\n        logits = model(X_tcr_batch, X_hla_batch)\n        _, predicted = torch.max(logits.data, 1)\n        probs = softmax(logits, dim=1)[:, 1]  \n        predictions.extend(predicted.cpu().numpy())\n        prob_predictions.extend(probs.cpu().numpy())\n        real_labels.extend(y_batch.cpu().numpy())\n\npredictions = np.array(predictions)\nprob_predictions = np.array(prob_predictions)\nreal_labels = np.array(real_labels).flatten()\n\nresults_df = pd.DataFrame({\n    'Predictions': predictions,\n    'Probability Predictions': prob_predictions,\n    'Real Labels': real_labels\n})\nresults_df.to_csv('independed_results.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2024-08-13T12:14:37.613393Z","iopub.status.idle":"2024-08-13T12:14:37.613825Z","shell.execute_reply.started":"2024-08-13T12:14:37.613626Z","shell.execute_reply":"2024-08-13T12:14:37.613643Z"},"trusted":true},"execution_count":null,"outputs":[]}]}